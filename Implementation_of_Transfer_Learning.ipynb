{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15F8jGyUdtrG"
   },
   "source": [
    "## __Transfer Learning__\n",
    "- Transfer learning refers to a technique in machine learning where a pre-trained model, typically trained on a large dataset, is used as a starting point for solving a different but related task.\n",
    "- It involves using models that were trained on one problem as a starting point for solving a related problem.\n",
    "- It is flexible, allowing the use of pre-trained models directly, as feature extraction preprocessing, and integrated into entirely new models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgCmoesorvHh"
   },
   "source": [
    "## Steps to be followed:\n",
    "1. Import the required libraries\n",
    "2. Add classifier layers\n",
    "3. Perform preprocessing and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKMViz1Ngp8Y"
   },
   "source": [
    "### Step 1: Import the required libraries\n",
    "\n",
    "- The **from tensorflow.keras.utils import load_img** loads an image file from the file system.\n",
    "\n",
    "- The **from tensorflow.keras.utils import img_to_array** converts an image loaded with load_img into a NumPy array.\n",
    "\n",
    "- The **from keras.applications.vgg16 import preprocess_input** preprocesses the input image array before feeding it to the VGG16 model. VGG16 expects the input images to be preprocessed in a specific way.\n",
    "\n",
    "- The **from keras.applications.vgg16 import VGG16** imports the VGG16 model architecture. VGG16 is a popular convolutional neural network model pre-trained on the ImageNet dataset for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5woHmJrJdtrK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:31:45.522882: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-07 21:31:46.838980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOC-NOTICE: GPU memory for this assignment is capped at 1024MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:31:52.571580: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_860Ql8kwv-"
   },
   "source": [
    "### Step 2: Add classifier layers\n",
    "- It demonstrates how to load a pre-trained VGG16 model without its classifier layers and then add new custom classifier layers on top of it.\n",
    "- The new model is defined by connecting the output of the pre-trained VGG16 model to a flattening layer. It is followed by a dense layer with 1024 units and ReLU activation and a dense layer with 10 units and Softmax activation for multi-class classification.\n",
    "- The model summary provides an overview of the architecture and layer configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg_model = VGG16(weights='imagenet',include_top=False,input_shape=(300,300,3))\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet',include_top=True,input_shape=(224,224,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138357544 (527.79 MB)\n",
      "Trainable params: 138357544 (527.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41472"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9*9*512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "pic = load_img(\"dog.jpg\",target_size=(224,224,3))\n",
    "image_array = img_to_array(pic)\n",
    "\n",
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array=image_array.reshape(1,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the custom image before passing to pre-defined model vgg_model\n",
    "\n",
    "image_array=preprocess_input(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 216ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=vgg_model.predict(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.94807174e-08, 5.79688786e-09, 8.30406943e-09, 1.74252746e-09,\n",
       "        1.44060138e-07, 1.00703339e-08, 6.88586477e-09, 1.77538510e-07,\n",
       "        1.41432497e-06, 6.93835389e-08, 1.81390369e-08, 2.40983873e-08,\n",
       "        2.93421571e-08, 1.61981347e-07, 8.97816861e-08, 9.10856812e-08,\n",
       "        3.32281580e-08, 2.34015388e-07, 4.43871251e-08, 2.52309622e-08,\n",
       "        7.38945687e-07, 1.13859926e-07, 2.91440273e-07, 2.00328395e-05,\n",
       "        8.13016243e-07, 6.38612860e-08, 1.57287801e-08, 3.70455098e-08,\n",
       "        4.21837711e-08, 1.55691833e-08, 1.13163523e-07, 1.38484225e-07,\n",
       "        1.46039199e-07, 6.14779196e-08, 3.69998389e-07, 8.72577317e-08,\n",
       "        2.64769596e-07, 8.89464076e-08, 9.25196275e-08, 5.95343454e-06,\n",
       "        6.85515289e-08, 2.10467075e-08, 9.54131920e-08, 1.03046091e-07,\n",
       "        8.83292444e-08, 1.24966988e-07, 5.41318116e-07, 7.02809260e-08,\n",
       "        1.08511176e-05, 3.38572370e-08, 8.74204815e-08, 1.23952859e-07,\n",
       "        2.09336068e-08, 3.96575501e-08, 3.31462324e-09, 3.19451594e-08,\n",
       "        7.65583419e-09, 2.43778331e-09, 2.18849472e-08, 1.11688925e-08,\n",
       "        8.79767104e-09, 4.08611207e-08, 1.13810144e-08, 1.70481123e-08,\n",
       "        1.38652227e-08, 6.34163655e-08, 1.66188174e-09, 1.09739240e-08,\n",
       "        2.14677454e-09, 3.97336297e-09, 5.63183777e-10, 1.12329852e-08,\n",
       "        1.52331903e-09, 3.89999810e-09, 1.59852398e-09, 9.91331572e-10,\n",
       "        2.46050003e-09, 2.87042279e-09, 5.67207215e-09, 1.59431384e-08,\n",
       "        9.93243443e-09, 7.73890861e-07, 5.57387750e-07, 2.56386077e-08,\n",
       "        5.56046800e-08, 9.50746610e-08, 6.38243910e-06, 1.15739522e-06,\n",
       "        4.13419130e-08, 3.76525509e-06, 2.85134778e-08, 7.07392478e-10,\n",
       "        2.86723822e-09, 3.25927091e-10, 8.10342868e-08, 2.48881915e-10,\n",
       "        2.49953813e-09, 1.65551015e-07, 8.55256275e-08, 4.62187836e-06,\n",
       "        1.44382113e-07, 8.41622239e-07, 3.36451826e-08, 9.70261112e-07,\n",
       "        1.68652309e-06, 1.87229460e-07, 7.23895113e-08, 6.90125361e-08,\n",
       "        6.46754827e-09, 2.07744630e-08, 5.02031972e-09, 3.78684906e-09,\n",
       "        2.42292458e-07, 5.40121732e-07, 2.06229025e-08, 3.51126737e-08,\n",
       "        1.00223527e-08, 1.13934595e-08, 3.55299368e-09, 4.84556715e-08,\n",
       "        1.29784503e-08, 3.54259311e-09, 1.24474642e-09, 1.07896581e-09,\n",
       "        6.82574424e-08, 2.58402764e-07, 1.39337279e-08, 1.34815753e-06,\n",
       "        2.26421388e-08, 5.46497631e-06, 1.28952550e-07, 6.27614014e-08,\n",
       "        2.41477494e-07, 1.51850643e-09, 1.31050712e-07, 1.44343639e-08,\n",
       "        2.05687201e-07, 4.91941762e-07, 1.34373028e-08, 2.18364633e-07,\n",
       "        2.44235050e-08, 2.48854747e-07, 3.03069712e-08, 4.19711142e-07,\n",
       "        1.59628613e-07, 1.05777633e-06, 4.87748321e-06, 1.05927231e-08,\n",
       "        4.86362284e-10, 1.18856260e-05, 7.47010108e-06, 1.59188694e-05,\n",
       "        3.31943229e-05, 8.29382916e-05, 5.84962363e-05, 9.40364480e-05,\n",
       "        4.90422171e-05, 2.82420751e-05, 4.37864946e-06, 7.15932183e-05,\n",
       "        4.38655916e-05, 1.06221414e-04, 5.80226406e-05, 6.30484545e-04,\n",
       "        1.09830908e-05, 5.49465449e-06, 7.89033038e-06, 8.61683111e-06,\n",
       "        1.72492160e-04, 1.36125775e-04, 1.33047215e-04, 4.78649372e-06,\n",
       "        2.31999493e-05, 2.45432766e-05, 5.74095284e-05, 2.76318780e-04,\n",
       "        3.15352314e-04, 3.01654927e-05, 5.91819063e-02, 1.28830565e-04,\n",
       "        4.50878433e-04, 5.22407033e-02, 5.26581607e-06, 1.18524267e-05,\n",
       "        8.29061028e-05, 6.15646059e-05, 9.83703194e-06, 1.41162457e-06,\n",
       "        3.44478394e-05, 1.70232943e-05, 3.44857021e-04, 3.14993777e-05,\n",
       "        1.65496624e-06, 2.22076778e-06, 6.97802679e-05, 5.94773746e-06,\n",
       "        1.60460331e-05, 1.41262844e-05, 8.59937791e-06, 2.55514607e-07,\n",
       "        1.33185193e-03, 6.43722842e-06, 2.76529841e-04, 4.41138855e-06,\n",
       "        7.92965075e-05, 2.21842536e-04, 8.18354602e-04, 1.25861272e-01,\n",
       "        3.57013568e-02, 1.08716227e-02, 1.05113133e-04, 5.87793998e-04,\n",
       "        4.91446117e-03, 4.74646076e-04, 3.33160249e-04, 6.29433198e-04,\n",
       "        9.69628990e-02, 7.69474573e-05, 1.32086323e-04, 4.57868539e-03,\n",
       "        5.54563245e-03, 1.34013942e-04, 9.58321467e-02, 5.88993316e-07,\n",
       "        1.64809285e-06, 5.15235615e-06, 6.58679755e-06, 3.36452977e-05,\n",
       "        2.00858712e-03, 5.82095643e-04, 5.65329810e-06, 1.45380391e-05,\n",
       "        2.38047251e-05, 7.04357808e-06, 9.21748870e-05, 3.25510155e-05,\n",
       "        1.81335461e-04, 2.75243906e-07, 1.38504183e-04, 5.36498883e-05,\n",
       "        2.81724060e-05, 2.36353608e-05, 6.25736197e-04, 3.55738332e-04,\n",
       "        1.14895352e-04, 1.00089856e-05, 5.43288828e-04, 1.29737513e-04,\n",
       "        6.01308857e-05, 5.61970483e-05, 1.55208763e-05, 6.58808276e-05,\n",
       "        4.67004185e-07, 1.31254219e-05, 1.50784443e-04, 2.13332794e-04,\n",
       "        1.16715702e-04, 8.05490464e-02, 1.38096759e-04, 2.99981639e-06,\n",
       "        1.03481732e-04, 3.92547508e-06, 1.56512051e-05, 1.08108713e-06,\n",
       "        2.53289431e-06, 3.19603481e-03, 1.24716554e-02, 3.91453862e-01,\n",
       "        2.48370598e-05, 5.38837821e-06, 5.25240685e-05, 1.01861403e-07,\n",
       "        1.71293505e-06, 9.70596466e-06, 1.71381657e-07, 4.87440950e-08,\n",
       "        1.09598170e-06, 8.94654448e-08, 2.40276051e-07, 3.07981427e-05,\n",
       "        1.04476058e-07, 6.74978082e-08, 1.68482160e-07, 8.31694464e-08,\n",
       "        1.21472894e-07, 4.77614094e-07, 1.04366177e-06, 3.39481375e-07,\n",
       "        1.61614668e-08, 2.83465695e-08, 2.45204053e-08, 9.68769200e-06,\n",
       "        9.69615485e-07, 2.78461528e-07, 2.85394744e-05, 1.03466867e-07,\n",
       "        4.08666994e-04, 4.14798421e-07, 1.18774039e-06, 2.44235275e-06,\n",
       "        1.10697396e-09, 1.49704231e-08, 2.30335462e-09, 6.69042211e-10,\n",
       "        1.34481670e-09, 4.86503779e-08, 4.40015091e-09, 3.18871436e-08,\n",
       "        6.11884632e-09, 4.68988937e-09, 6.85258996e-08, 1.89939357e-07,\n",
       "        1.40514516e-08, 5.25449906e-10, 3.07762926e-09, 3.48370328e-08,\n",
       "        4.32341407e-09, 3.22727445e-08, 5.22505650e-10, 3.00704150e-09,\n",
       "        2.54376076e-10, 7.07235936e-10, 1.99173678e-10, 7.49521889e-10,\n",
       "        5.80548498e-09, 6.87858992e-10, 3.13076720e-09, 2.24756334e-07,\n",
       "        2.25984778e-08, 3.06109094e-09, 8.83549447e-08, 1.90536343e-06,\n",
       "        2.87270723e-07, 1.03180957e-08, 1.86756699e-09, 7.41942827e-08,\n",
       "        1.21106484e-06, 5.03679054e-08, 1.71522942e-07, 1.64482845e-08,\n",
       "        5.03447595e-08, 3.35977938e-06, 3.69798556e-08, 6.68963835e-08,\n",
       "        3.07524687e-07, 1.75099592e-06, 4.94302071e-07, 1.60282568e-07,\n",
       "        7.73727428e-04, 3.76938669e-06, 2.09285858e-07, 8.51677129e-09,\n",
       "        6.00259131e-09, 2.19845617e-08, 1.12405405e-06, 5.43506439e-06,\n",
       "        6.70070904e-06, 5.30467196e-06, 7.71306134e-07, 7.45537193e-07,\n",
       "        1.10341143e-05, 1.17962520e-08, 7.79412872e-08, 1.48702142e-07,\n",
       "        2.79872040e-07, 1.84632682e-07, 4.91523588e-06, 8.71356065e-07,\n",
       "        1.61395644e-06, 6.22402979e-07, 9.42736307e-08, 1.18474372e-06,\n",
       "        5.02027933e-06, 5.43048664e-05, 1.22616882e-07, 8.88934526e-09,\n",
       "        2.00547063e-07, 4.12153298e-07, 2.07963780e-07, 1.39234997e-08,\n",
       "        3.06053039e-07, 2.17517027e-07, 1.15197778e-07, 3.11747613e-07,\n",
       "        4.62562610e-08, 2.28582144e-06, 1.16298600e-06, 1.84209858e-09,\n",
       "        1.11445004e-07, 1.32480906e-08, 2.68445959e-08, 3.02801624e-08,\n",
       "        2.86139268e-09, 5.62038804e-10, 1.46863087e-07, 3.09661274e-09,\n",
       "        1.56417990e-09, 3.04562455e-08, 9.62734159e-09, 3.92697572e-08,\n",
       "        1.79222992e-09, 1.66853582e-07, 4.99877340e-09, 5.92489835e-10,\n",
       "        2.93173184e-08, 5.17967962e-08, 9.96332439e-09, 3.00331742e-08,\n",
       "        2.54172630e-08, 6.18095555e-07, 2.30430501e-08, 4.05431244e-09,\n",
       "        5.69303165e-06, 4.60283189e-08, 3.93390875e-09, 2.53429899e-09,\n",
       "        3.04786499e-06, 4.26948020e-07, 2.48801115e-07, 2.78204448e-06,\n",
       "        1.29781981e-07, 2.82793820e-07, 3.52894034e-07, 2.50636023e-09,\n",
       "        1.81444690e-08, 8.04823870e-08, 1.54506210e-07, 1.69088923e-06,\n",
       "        1.31039019e-06, 2.90126882e-05, 2.16288232e-08, 1.07452811e-08,\n",
       "        4.56926905e-08, 4.66431175e-06, 4.89269660e-05, 1.57965451e-06,\n",
       "        3.20914211e-08, 6.79270045e-07, 4.18427248e-08, 1.07322542e-08,\n",
       "        2.52652427e-07, 1.70373411e-07, 3.54764418e-09, 9.92026106e-09,\n",
       "        2.55969439e-07, 9.13899657e-06, 2.24458923e-08, 2.94671986e-06,\n",
       "        1.43768544e-08, 3.78757967e-08, 8.85889051e-08, 5.13189935e-09,\n",
       "        3.87712582e-08, 2.01047907e-08, 2.51797005e-09, 1.17949085e-07,\n",
       "        3.56497019e-08, 4.76290438e-07, 1.90637479e-07, 6.75813467e-08,\n",
       "        1.58105604e-06, 3.72580899e-08, 1.09928200e-08, 3.70591704e-04,\n",
       "        5.98109429e-09, 6.69281164e-09, 1.12315435e-09, 1.72032344e-08,\n",
       "        1.86154438e-07, 8.02036837e-09, 2.21170112e-07, 2.99062144e-08,\n",
       "        1.20220193e-06, 2.75538298e-07, 2.45183465e-08, 1.71977881e-08,\n",
       "        1.36150502e-09, 3.57804053e-09, 6.42076259e-07, 1.28463654e-07,\n",
       "        2.28682637e-08, 4.60127829e-08, 1.80997759e-08, 1.80469311e-08,\n",
       "        1.98817460e-08, 1.13379199e-08, 1.37745415e-09, 2.66515343e-07,\n",
       "        1.40215604e-06, 6.66441167e-07, 7.30871763e-09, 4.50212418e-08,\n",
       "        6.70446170e-08, 3.15526161e-09, 1.63409037e-08, 6.78322243e-09,\n",
       "        1.53170262e-07, 3.09886588e-08, 5.28520827e-09, 1.71770704e-08,\n",
       "        4.07512635e-10, 2.18432437e-08, 3.92689330e-08, 1.01134468e-07,\n",
       "        7.18990236e-08, 4.50868107e-08, 1.90453662e-08, 2.21473201e-07,\n",
       "        5.11830471e-08, 7.35753147e-09, 2.37534383e-08, 4.05952143e-08,\n",
       "        3.51653533e-08, 1.83775484e-08, 1.61916802e-07, 4.16232098e-07,\n",
       "        1.28332669e-08, 4.69371075e-09, 1.62922987e-07, 1.11947678e-07,\n",
       "        2.73630967e-08, 4.92307990e-08, 1.06641473e-05, 1.43108537e-06,\n",
       "        3.04877279e-09, 1.86973477e-08, 1.00630189e-08, 1.13035012e-08,\n",
       "        1.06017531e-07, 3.25844462e-06, 1.05387592e-07, 2.14269699e-06,\n",
       "        1.74149750e-09, 1.04940001e-09, 2.13618094e-07, 4.34581082e-09,\n",
       "        1.30063739e-07, 1.01754574e-06, 5.41726575e-09, 7.98238034e-06,\n",
       "        3.43752382e-09, 1.85153279e-08, 9.77023049e-08, 1.00008847e-05,\n",
       "        2.29816006e-08, 8.57005134e-08, 1.38017076e-09, 3.48221812e-10,\n",
       "        2.36348985e-08, 3.58297356e-08, 5.29738964e-09, 5.62016211e-08,\n",
       "        1.35605808e-06, 1.24467601e-08, 1.97243537e-08, 2.88101578e-08,\n",
       "        3.24173932e-09, 5.07279090e-08, 1.82470927e-08, 2.17617782e-08,\n",
       "        1.15802004e-06, 3.20308580e-09, 1.90205185e-06, 7.13464343e-10,\n",
       "        1.44568593e-10, 7.12586123e-09, 1.95720542e-08, 3.55001317e-09,\n",
       "        1.39280291e-06, 1.11866738e-08, 2.34150235e-07, 3.34516670e-07,\n",
       "        4.64722589e-08, 7.56020953e-08, 7.89456317e-05, 6.12976736e-09,\n",
       "        6.69833855e-10, 1.57608824e-08, 8.46463138e-07, 3.57427048e-08,\n",
       "        2.21989502e-08, 1.52562283e-08, 1.57460693e-08, 1.48082868e-09,\n",
       "        4.71487693e-09, 4.83681163e-07, 8.69791172e-09, 4.44327497e-06,\n",
       "        1.37164236e-08, 4.19399043e-07, 1.64420424e-08, 2.23936372e-08,\n",
       "        4.38091474e-09, 1.92326624e-07, 1.17409424e-08, 6.01863377e-08,\n",
       "        1.03014713e-06, 5.83431026e-10, 4.76698752e-08, 5.61512969e-09,\n",
       "        2.35635547e-08, 9.01080739e-08, 3.04948543e-07, 4.39356729e-09,\n",
       "        4.45982202e-08, 4.98453332e-08, 2.77075678e-08, 2.23474173e-09,\n",
       "        1.58197068e-07, 1.00285057e-07, 8.33177864e-07, 4.42597866e-07,\n",
       "        3.26491417e-10, 2.20236327e-08, 4.45764528e-08, 2.29772650e-06,\n",
       "        9.20814784e-07, 2.21951282e-07, 6.64046196e-09, 9.37771318e-08,\n",
       "        6.10769106e-08, 6.10028610e-06, 1.81058283e-07, 2.76404655e-09,\n",
       "        8.29716651e-09, 6.32944008e-09, 2.19160327e-07, 5.96797500e-10,\n",
       "        3.39655131e-08, 5.12465874e-08, 2.15001994e-09, 9.90170861e-07,\n",
       "        6.36727870e-09, 3.85053511e-07, 4.18254720e-09, 5.84846021e-08,\n",
       "        9.98857441e-09, 1.67411443e-07, 1.90689775e-06, 1.22026881e-06,\n",
       "        3.92889987e-09, 9.91277673e-08, 2.04302015e-08, 2.40800915e-07,\n",
       "        2.65776748e-07, 7.81396725e-09, 7.02810837e-07, 1.44280406e-07,\n",
       "        1.51461101e-08, 1.91322601e-06, 2.69319514e-07, 4.13774748e-09,\n",
       "        4.86396132e-08, 7.30541797e-06, 5.00064257e-09, 9.22320780e-08,\n",
       "        2.55710053e-09, 2.25267396e-08, 3.07028465e-08, 3.79806231e-08,\n",
       "        3.76434798e-07, 4.22355761e-10, 4.37568737e-09, 1.37369693e-09,\n",
       "        7.91707961e-08, 1.32919036e-08, 5.61316149e-08, 6.26958396e-08,\n",
       "        4.68951322e-09, 1.50042900e-09, 1.93577243e-08, 1.16563925e-07,\n",
       "        5.60684867e-08, 5.93874212e-08, 6.42019927e-07, 1.24342074e-08,\n",
       "        3.54020915e-04, 1.95409555e-07, 2.35626899e-07, 3.12659161e-08,\n",
       "        7.95297365e-06, 3.07783182e-07, 1.48742416e-07, 2.76890244e-08,\n",
       "        8.15478529e-09, 2.50800181e-08, 3.75688131e-07, 1.20062582e-09,\n",
       "        8.55119708e-09, 1.09247207e-08, 4.91025753e-09, 4.54693030e-08,\n",
       "        4.56029241e-08, 1.44205364e-06, 2.69341838e-09, 9.55049245e-07,\n",
       "        3.88483045e-07, 3.73485790e-07, 6.38801083e-08, 4.05172614e-07,\n",
       "        6.95235883e-07, 1.99672272e-07, 2.89248362e-07, 2.97913562e-06,\n",
       "        2.27395930e-07, 1.96107393e-07, 8.68347350e-09, 7.71132136e-08,\n",
       "        2.04009884e-05, 3.54243959e-08, 7.34057835e-07, 8.04577525e-08,\n",
       "        3.27625038e-09, 3.60045416e-09, 7.09877526e-08, 3.18656816e-08,\n",
       "        3.64778521e-06, 6.60531953e-07, 2.59478696e-07, 3.83749523e-07,\n",
       "        1.45224851e-06, 3.27004500e-07, 1.15235807e-05, 6.91310333e-08,\n",
       "        1.05305968e-08, 2.20540262e-08, 5.07831599e-09, 1.36478153e-08,\n",
       "        8.79625190e-07, 5.11270914e-10, 7.06339591e-08, 4.74286111e-07,\n",
       "        1.45798310e-07, 8.44023873e-07, 8.04311817e-09, 2.08182147e-08,\n",
       "        9.68617314e-07, 7.51141613e-07, 2.83036172e-08, 7.81701175e-08,\n",
       "        2.60788312e-07, 2.49559040e-08, 3.33725936e-08, 1.86716171e-08,\n",
       "        1.09521148e-08, 6.16108720e-09, 1.50975108e-08, 6.45396696e-08,\n",
       "        7.02428826e-09, 5.46189982e-09, 9.61328297e-08, 6.86082942e-08,\n",
       "        1.68902361e-07, 5.41293332e-07, 1.57303305e-07, 3.99189162e-08,\n",
       "        8.52695337e-07, 1.71509029e-07, 2.97366142e-07, 1.71151289e-08,\n",
       "        2.25045028e-07, 3.01293630e-06, 1.53421276e-09, 1.68725194e-08,\n",
       "        1.64243961e-08, 5.12488668e-07, 1.11178777e-09, 1.14028637e-06,\n",
       "        3.45155822e-05, 5.56066254e-07, 7.20303177e-08, 8.79200428e-08,\n",
       "        4.38646026e-08, 2.86529348e-06, 6.70010447e-09, 6.87947619e-08,\n",
       "        2.98354550e-08, 1.07135156e-09, 1.35607294e-07, 1.28508537e-08,\n",
       "        1.77121908e-08, 1.05505855e-07, 4.31688761e-07, 1.21981117e-07,\n",
       "        6.48496368e-08, 5.88914446e-08, 1.23778975e-07, 1.88552818e-08,\n",
       "        2.18025686e-09, 2.02562536e-08, 3.48748386e-09, 2.81777290e-07,\n",
       "        2.46791819e-06, 1.32925254e-06, 1.29968312e-08, 4.79510391e-07,\n",
       "        6.80358951e-08, 1.42169995e-07, 1.77722566e-08, 5.41103091e-08,\n",
       "        1.70000867e-08, 1.07562869e-07, 3.56018646e-08, 7.12107540e-10,\n",
       "        1.64953875e-07, 5.86570473e-04, 9.93543154e-07, 9.04810626e-09,\n",
       "        2.98741043e-07, 4.73109196e-09, 1.47858286e-08, 9.21250489e-07,\n",
       "        2.02260164e-09, 6.01390013e-08, 1.40697951e-08, 1.45820700e-09,\n",
       "        8.19780743e-10, 3.77482898e-08, 2.68684948e-06, 2.01255084e-08,\n",
       "        7.34538830e-09, 1.64071978e-09, 1.04084483e-08, 3.93366861e-07,\n",
       "        1.05892894e-08, 3.11328392e-07, 3.91884072e-07, 6.13151983e-08,\n",
       "        2.74793308e-07, 2.89805002e-09, 2.02433927e-08, 1.69440582e-07,\n",
       "        1.82765962e-08, 1.18855892e-09, 6.03273520e-08, 1.26369935e-06,\n",
       "        3.74436922e-07, 4.47029095e-07, 2.15038995e-06, 1.24655697e-09,\n",
       "        4.91299886e-07, 2.59757968e-07, 2.90380876e-06, 4.17862580e-08,\n",
       "        2.47287659e-07, 5.19487003e-07, 1.34100816e-07, 3.62923958e-09,\n",
       "        4.65007659e-08, 2.78385688e-08, 4.25020407e-05, 2.33150990e-06,\n",
       "        2.13691476e-03, 5.19919130e-09, 3.26694027e-09, 9.79059791e-07,\n",
       "        8.79600925e-09, 4.55696014e-09, 6.41750333e-08, 2.01970742e-08,\n",
       "        7.94829091e-09, 3.95605468e-08, 1.14100473e-07, 2.07948005e-08,\n",
       "        1.52181272e-08, 1.37431698e-07, 9.62384092e-08, 3.41399691e-08,\n",
       "        1.51955906e-08, 3.63848791e-08, 3.41182249e-06, 3.56932239e-09,\n",
       "        3.47176154e-07, 1.85139513e-08, 1.90657845e-09, 7.60708652e-09,\n",
       "        4.18424906e-06, 2.26221104e-08, 4.63948746e-09, 1.93849672e-07,\n",
       "        5.30210755e-08, 1.92057641e-08, 5.94648043e-07, 7.11583770e-09,\n",
       "        2.67506395e-09, 8.24089241e-09, 7.23380253e-08, 8.61765681e-09,\n",
       "        2.79981069e-08, 8.27493007e-09, 1.22490073e-05, 3.98265776e-09,\n",
       "        6.60650059e-08, 1.45301793e-09, 3.69431796e-09, 3.03133696e-09,\n",
       "        5.15746912e-08, 1.58301205e-07, 4.41250922e-05, 3.47537906e-07,\n",
       "        3.67068446e-06, 2.56839314e-08, 3.87102682e-06, 2.70327973e-07,\n",
       "        2.86394943e-08, 9.66303126e-09, 2.04185824e-09, 8.06258171e-08,\n",
       "        4.85226481e-09, 2.00816364e-09, 2.54409809e-08, 4.00957418e-07,\n",
       "        4.15047708e-07, 4.87667364e-08, 1.93764849e-09, 3.29356510e-07,\n",
       "        1.36990438e-05, 2.22319159e-08, 1.21181998e-07, 2.49353960e-08,\n",
       "        2.73922107e-10, 7.44180042e-08, 5.91258509e-09, 1.57294600e-09,\n",
       "        8.36613534e-09, 1.14917087e-09, 1.39315426e-09, 4.75478457e-09,\n",
       "        1.16575485e-07, 3.67817520e-05, 5.81162274e-09, 1.63169133e-07,\n",
       "        1.03975495e-07, 5.89019389e-10, 1.86008098e-08, 2.00380637e-08,\n",
       "        9.88942883e-09, 2.38552673e-07, 8.45344630e-08, 3.18999192e-08,\n",
       "        3.30695071e-09, 1.77555345e-10, 3.82417262e-08, 4.34623573e-08,\n",
       "        3.59105350e-08, 2.63756856e-08, 5.66614666e-09, 6.65691630e-07,\n",
       "        3.64014852e-07, 1.55414326e-09, 5.43116829e-10, 7.99044120e-09,\n",
       "        2.19980989e-09, 3.66720265e-10, 1.19980692e-08, 1.52508672e-09,\n",
       "        4.67170302e-09, 3.46790124e-10, 2.02312819e-07, 8.19731127e-09,\n",
       "        2.59050181e-09, 8.61312913e-07, 5.98200733e-09, 5.19591703e-10,\n",
       "        1.82384208e-09, 2.55627768e-08, 4.03103506e-08, 2.15276108e-09,\n",
       "        1.06302582e-06, 1.59169375e-07, 7.72694264e-08, 2.74600848e-06,\n",
       "        8.36713667e-08, 8.85059848e-08, 4.30854925e-06, 2.03929740e-05,\n",
       "        3.79364792e-07, 2.83715622e-06, 3.93028495e-06, 4.26798827e-08,\n",
       "        3.68332955e-08, 1.50415610e-06, 7.99597444e-07, 3.88148269e-09,\n",
       "        4.47701495e-07, 4.31483027e-09, 1.05594145e-09, 4.66575926e-07,\n",
       "        2.42960567e-08, 3.58276857e-08, 3.11867254e-10, 1.84026270e-08,\n",
       "        3.61264583e-08, 2.51836525e-08, 1.29280000e-08, 2.76295339e-07,\n",
       "        1.49401593e-08, 1.22152566e-09, 1.87821414e-07, 8.39014956e-06]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([267])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4779,
     "status": "ok",
     "timestamp": 1716031468674,
     "user": {
      "displayName": "Vikas Singh",
      "userId": "04375885343580620832"
     },
     "user_tz": -330
    },
    "id": "h95JEG-VdtrM",
    "outputId": "feb28546-dc50-4fef-d918-c528dd756671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40416074 (154.18 MB)\n",
      "Trainable params: 40416074 (154.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "class1 = Dense(1024, activation='relu')(flat1)\n",
    "output = Dense(10, activation='softmax')(class1)\n",
    "\n",
    "model = Model(inputs=model.inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1000)              25089000  \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               512512    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40316713 (153.80 MB)\n",
      "Trainable params: 25602025 (97.66 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Since the above Trainable parameter is 40416074, we need to add froxen layer to reduce the trainable parameters\n",
    "# shown below before doing sequental model for the custom model\n",
    "\n",
    "# Frozen reduces the parameter coming from the pre-trained model which used in VGG16, so it is now 25602025\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "#vgg_model = VGG16(weights='imagenet',include_top=False,input_shape=(300,300,3))\n",
    "vgg_model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(224,224,3)))\n",
    "model.add(vgg_model)\n",
    "#Flatten the ouput from the convolutional layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the first fully connected layer\n",
    "model.add(Dense(1000,activation='relu')) # fully connected\n",
    "# Add the first fully connected layer \n",
    "model.add(Dense(512,activation='relu')) # fully connected\n",
    "model.add(Dense(1,activation='softmax'))\n",
    "\n",
    "# flat1 = Flatten()(model.layers[-1].output)\n",
    "# class1 = Dense(1024, activation='relu')(flat1)\n",
    "# output = Dense(10, activation='softmax')(class1)\n",
    "\n",
    "#model = Model(inputs=model.inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 5, 5, 64)          294976    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15050881 (57.41 MB)\n",
      "Trainable params: 336193 (1.28 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Further reducing trainable params from 25602025 to less, need to add more convolutional layers and max pool\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Flatten\n",
    "\n",
    "#vgg_model = VGG16(weights='imagenet',include_top=False,input_shape=(300,300,3))\n",
    "vgg_model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(224,224,3)))\n",
    "model.add(vgg_model)\n",
    "\n",
    "#Adding first convolutional layer\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "\n",
    "#Adding second max pooling layer\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "#Flatten the ouput from the convolutional layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the first fully connected layer\n",
    "model.add(Dense(128,activation='relu')) # fully connected <- Reducing from 1000 to 128 and 512 to 64 will give 336193 else goes in million\n",
    "# Add the first fully connected layer \n",
    "model.add(Dense(64,activation='relu')) # fully connected\n",
    "model.add(Dense(1,activation='softmax'))\n",
    "\n",
    "# flat1 = Flatten()(model.layers[-1].output)\n",
    "# class1 = Dense(1024, activation='relu')(flat1)\n",
    "# output = Dense(10, activation='softmax')(class1)\n",
    "\n",
    "#model = Model(inputs=model.inputs, outputs=output)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3tLfn7WdtrN"
   },
   "source": [
    "**Observation**\n",
    "- Running the example means that the new model is ready for training and summarizes the model architecture.\n",
    "- The output of the last pooling layer is flattened, and the new fully connected layers are added.\n",
    "- The weights of the VGG16 model and the new model will all be trained together on the new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DWAS8owlYbP"
   },
   "source": [
    "### Step 3: Perform preprocessing and feature extraction\n",
    "- The image is loaded from a file and preprocessed to meet the input requirements of the VGG16 model (resizing, converting to a numpy array, and reshaping).\n",
    "\n",
    "- The modified model predicts and extracts features from the input image, resulting in a feature vector with a specific shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19030,
     "status": "ok",
     "timestamp": 1716031487692,
     "user": {
      "displayName": "Vikas Singh",
      "userId": "04375885343580620832"
     },
     "user_tz": -330
    },
    "id": "pn9hQjZCdtrN",
    "outputId": "cf064a53-5ed4-4143-91cb-24f07faaa76e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 300ms/step\n",
      "(1, 4096)\n"
     ]
    }
   ],
   "source": [
    "image = load_img('dog.jpg', target_size=(224, 224))\n",
    "image = img_to_array(image)\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "image = preprocess_input(image)\n",
    "model = VGG16()\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "features = model.predict(image)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# img_height = 180\n",
    "# img_width = 180\n",
    "\n",
    "\n",
    "# train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#   data_dir,\n",
    "#   validation_split=0.2,\n",
    "#   subset=\"training\",\n",
    "#   seed=123,\n",
    "#   image_size=(img_height, img_width),\n",
    "#   batch_size=batch_size)\n",
    "\n",
    "# val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#   data_dir,\n",
    "#   validation_split=0.2,\n",
    "#   subset=\"Validation\",\n",
    "#   seed=123,\n",
    "#   image_size=(img_height, img_width),\n",
    "#   batch_size=batch_size)\n",
    "\n",
    "#Result\n",
    "# Found 3670 files belonging to 5 classes.\n",
    "# Using 2936 files for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image, apply augmentation and do preprocessing\n",
    "# to train the model do data augmentation while training\n",
    "# preprocessing comes from vgg16 model\n",
    "\n",
    "data_gen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                             horizontal_flip=True,\n",
    "                             width_shift_range=0.2,\n",
    "                             zoom_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train = data_gen.flow_from_directory(data_dir,target_size=(224,224),class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/local/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/local/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/local/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n      self._run_once()\n    File \"/usr/local/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n      handle._run()\n    File \"/usr/local/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_79/2289807549.py\", line 2, in <cell line: 2>\n      model.fit(train,epochs=2,steps_per_epoch=20,\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/losses.py\", line 2354, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/backend.py\", line 5762, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [32,4096] and labels shape [160]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_11730]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_79/2289807549.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlivelossplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlotLossesKerasTF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(train,epochs=2,steps_per_epoch=20,\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPlotLossesKerasTF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/local/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/local/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/local/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n      self._run_once()\n    File \"/usr/local/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n      handle._run()\n    File \"/usr/local/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_79/2289807549.py\", line 2, in <cell line: 2>\n      model.fit(train,epochs=2,steps_per_epoch=20,\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/losses.py\", line 2354, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/backend.py\", line 5762, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [32,4096] and labels shape [160]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_11730]"
     ]
    }
   ],
   "source": [
    "from livelossplot import PlotLossesKerasTF\n",
    "model.fit(train,epochs=2,steps_per_epoch=20,\n",
    "  callbacks=[PlotLossesKerasTF()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jwvk_m95mR7D"
   },
   "source": [
    "**Observation**\n",
    "\n",
    "- The VGG16 model weights are downloaded and loaded successfully, and the extracted features from the input image have a shape of (1, 4096)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
